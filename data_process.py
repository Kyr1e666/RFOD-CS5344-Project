import pandas as pd
import ast
import json
from typing import List, Dict, Any, Set


def parse_list_field(value: Any) -> List:
    """å®‰å…¨åœ°è§£æå­—ç¬¦ä¸²å½¢å¼çš„listå­—æ®µï¼ˆå¦‚stackAddressesã€argsï¼‰"""
    if pd.isna(value):
        return []
    if isinstance(value, list):
        return value
    try:
        return ast.literal_eval(str(value))
    except Exception:
        return []


def extract_arg_features(df: pd.DataFrame, args_col: str = "args") -> pd.DataFrame:
    """å±•å¹³argså­—æ®µ"""
    if args_col not in df.columns:
        print(f"âš ï¸ è­¦å‘Šï¼šCSVä¸­ä¸å­˜åœ¨ '{args_col}' åˆ—ï¼Œè·³è¿‡ args ç‰¹å¾æå–ã€‚")
        return df

    all_feature_names: Set[str] = set()
    feature_types: Dict[str, Set[str]] = {}

    for args_str in df[args_col]:
        for arg in parse_list_field(args_str):
            if isinstance(arg, dict) and "name" in arg:
                name = arg["name"]
                all_feature_names.add(name)
                t = arg.get("type", "unknown")
                feature_types.setdefault(name, set()).add(t)

    all_feature_names = sorted(list(all_feature_names))

    flattened_features = []
    for args_str in df[args_col]:
        feature_map = {name: None for name in all_feature_names}
        for arg in parse_list_field(args_str):
            if isinstance(arg, dict) and "name" in arg and "value" in arg:
                feature_map[arg["name"]] = arg["value"]
        flattened_features.append(feature_map)

    args_df = pd.DataFrame(flattened_features)
    df = pd.concat([df.reset_index(drop=True), args_df.reset_index(drop=True)], axis=1)
    
    print(f"âœ… args åˆ—å·²å±•å¹³ï¼Œæ–°å¢ {len(all_feature_names)} ä¸ªç‰¹å¾ã€‚")
    return df

def convert_dtypes_for_training(df: pd.DataFrame) -> pd.DataFrame:
    """å°† timestampã€argsNumã€stack_depth è½¬ä¸ºæ•°å€¼å‹ï¼Œå…¶ä»–å…¨éƒ¨ä¸ºåˆ†ç±»å‹ã€‚"""
    numeric_cols = ["timestamp", "argsNum", "stack_depth"]
    for col in df.columns:
        if col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        elif col != "args":
            df[col] = df[col].astype(str)
    print(f"âœ… ç±»å‹è½¬æ¢å®Œæˆï¼š{len(numeric_cols)} æ•°å€¼å‹ç‰¹å¾ï¼Œå…¶ä½™ä¸ºåˆ†ç±»å‹ã€‚")
    return df


def clean_csv(input_path: str, output_path: str, process_args: bool = True, save: bool = True):
    """
    ä¸»æ¸…æ´—å‡½æ•°ï¼šå¢åŠ äº† processId åˆ†ç»„æ—¶é—´å½’ä¸€åŒ–
    """
    print(f"ğŸ”§ å¼€å§‹å¤„ç†æ–‡ä»¶ï¼š{input_path}")
    df = pd.read_csv(input_path)

    # stack_depth ç‰¹å¾
    if "stackAddresses" in df.columns:
        df["stackAddresses"] = df["stackAddresses"].apply(parse_list_field)
        df["stack_depth"] = df["stackAddresses"].apply(len)
        print("âœ… stack_depth ç‰¹å¾å·²è®¡ç®—ã€‚")

    # åˆ é™¤æŒ‡å®šåˆ—
    drop_cols = ["threadId", "eventId", "stackAddresses"]
    df = df.drop(columns=[col for col in drop_cols if col in df.columns], errors="ignore")
    print(f"âœ… åˆ é™¤äº†åˆ—ï¼š{drop_cols}")

    # å±•å¹³ args
    args_col_present = "args" in df.columns
    if process_args and args_col_present:
        df = extract_arg_features(df, args_col="args")
        df = df.drop(columns=["args"], errors="ignore")
    elif not process_args and args_col_present:
        df = df.drop(columns=["args"], errors="ignore")
        print("â­ï¸ å·²è·³è¿‡ 'args' åˆ—çš„å¤„ç†å¹¶å°†å…¶åˆ é™¤ã€‚")
    elif process_args and not args_col_present:
        print("âš ï¸ è­¦å‘Šï¼šè®¾ç½®äº†å¤„ç† 'args'ï¼Œä½† CSV ä¸­ä¸å­˜åœ¨è¯¥åˆ—ã€‚")

    # âœ… æ–°å¢ï¼šæŒ‰ processId åˆ†ç»„å½’ä¸€åŒ– timestamp
    if "processId" in df.columns and "timestamp" in df.columns:
        df["timestamp"] = pd.to_numeric(df["timestamp"], errors="coerce")
        df["timestamp"] = df.groupby("processId")["timestamp"].transform(lambda x: x - x.min())
        print("âœ… å·²å®ŒæˆæŒ‰ processId åˆ†ç»„çš„ timestamp å½’ä¸€åŒ–ã€‚")
    else:
        print("âš ï¸ ç¼ºå°‘ processId æˆ– timestamp åˆ—ï¼Œè·³è¿‡æ—¶é—´å½’ä¸€åŒ–ã€‚")

    # ç±»å‹è½¬æ¢
    df = convert_dtypes_for_training(df)

    if save:
        df.to_csv(output_path, index=False)
        print(f"\nğŸ‰ å¤„ç†å®Œæ¯•ï¼ŒCleaned data saved to: {output_path}")
    return df


if __name__ == "__main__":
    input_file = "data/processes_train.csv"
    output_file = "data/cleaned_train.csv"
   
    SHOULD_PROCESS_ARGS = False
    save = True

    clean_csv(
        input_path=input_file, 
        output_path=output_file, 
        process_args=SHOULD_PROCESS_ARGS,
        save=True
    )
